#!/usr/bin/env python

# This Source Code Form is subject to the terms of the Mozilla Public
# License, v. 2.0. If a copy of the MPL was not distributed with this
# file, You can obtain one at https://mozilla.org/MPL/2.0/.

# Usage: python socorro/schemas/validate_raw_crash.py [DIR]

from itertools import zip_longest
import json
import os
import pathlib

import click
import jsonschema
import yaml

from socorro.lib.libooid import is_crash_id_valid
from socorro.lib.librequests import session_with_retries
from socorro.lib.libsocorrodataschema import (
    compile_pattern_re,
    get_schema,
    SocorroDataReducer,
    split_path,
    transform_schema,
    validate_instance,
)
from socorro.schemas import get_file_content


HERE = os.path.dirname(__file__)


RAW_CRASH_SCHEMA = get_schema("raw_crash.schema.yaml")


CRASH_ANNOTATIONS_URL = (
    "https://hg.mozilla.org/mozilla-central/raw-file/tip/toolkit/crashreporter/"
    + "CrashAnnotations.yaml"
)


class InvalidSchemaError(Exception):
    pass


class SchemaKeyLogger:
    def __init__(self):
        # Set of (key, type)
        self.keys = set()

    def __call__(self, path, schema):
        if path and not path.endswith(".[]"):
            types = schema["type"]
            if not isinstance(schema["type"], list):
                types = [types]
            for type_ in types:
                self.keys.add((path, type_))
        return schema


PYTHON_TO_DATA = {
    str: "string",
    float: "number",
    int: "integer",
    type(None): "null",
    bool: "boolean",
    list: "array",
    dict: "object",
}


class DocumentKeys:
    def __init__(self):
        # Set of (key, type)
        self.keys = set()

    def log_keys(self, crash):
        def traverse(crash, path):
            if isinstance(crash, dict):
                for key, value in crash.items():
                    traverse(value, path=f"{path}.{key}")

            elif isinstance(crash, list):
                for item in crash:
                    traverse(item, path=f"{path}.[]")

            # Add non-arrays to the keys set
            if path and not path.endswith(".[]"):
                type_ = PYTHON_TO_DATA[type(crash)]
                self.keys.add((path, type_))

        traverse(crash, path="")


def match_key(schema_key, document_key):
    """Determines whether a key matches

    The schema_key can contain regex parts. This accounts for that.

    :arg str schema_key: the key from the schema which can contain regex parts
    :arg str document_key: the key from the document

    :returns: boolean

    """
    if "(re:" not in schema_key:
        return schema_key == document_key

    schema_parts = split_path(schema_key)
    doc_parts = split_path(document_key)

    for schema_part, doc_part in zip_longest(schema_parts, doc_parts, fillvalue=""):
        if "(re:" in schema_part:
            pattern_re = compile_pattern_re(schema_part[4:-1])
            if not pattern_re.match(doc_part):
                return False

        elif schema_part != doc_part:
            return False

    return True


def generate_raw_crash_list(datapath):
    """Generates a list of raw crash Path instances found in datapath

    If datapath points to a directory with raw crash files in it, then this will
    return a list of Path instances for those raw crash files.

    If datapath points to a directory structure generated by fetch_crash_data, then
    this will return a list of Path instances for raw crash files found in that
    data structure.

    This will ignore any files in those lists where the filename is not a crash id.

    :arg datapath: a Path pointing to the directory to look for raw crash files

    :returns: list of Path instances

    """
    # If datapath / "v1" exists, then datapath is a directory structure that is the
    # output of fetch_crash_data, so we need to pull out the raw crash files from that
    if (datapath / "v1").exists():
        raw_crash_files = list((datapath / "v1" / "raw_crash").rglob("*"))

    else:
        raw_crash_files = list(datapath.glob("*"))

    raw_crash_files = [
        path for path in raw_crash_files if is_crash_id_valid(str(path.name))
    ]
    return raw_crash_files


@click.command()
@click.argument("crashdir")
@click.pass_context
def validate_and_test(ctx, crashdir):
    """Validates the schema as a valid schema and against example data.

    This validates that the raw_crash schema is a valid socorro-data-1-0-0 schema.

    Then it uses the raw_crash schema to validate raw crash files in the provided
    CRASHDIR. You should use "socorro-cmd fetch_crash_data" to build the CRASHDIR.

    At the end, it'll report any validation errors as well as list annotations that are
    in the raw_crash schema that aren't in example data and annotations that are in the
    example data that aren't in the raw_crash schema.
    """

    socorro_data_schema = get_file_content("socorro-data-1-0-0.schema.yaml")
    jsonschema.Draft7Validator.check_schema(socorro_data_schema)
    click.echo("socorro-data-1-0-0.schema.yaml is a valid jsonschema.")

    jsonschema.validate(instance=RAW_CRASH_SCHEMA, schema=socorro_data_schema)
    click.echo("raw crash schema is a valid socorro data schema.")

    # Fetch crash report data from a Super Search URL
    datapath = pathlib.Path(crashdir).resolve()
    if not datapath.is_dir():
        raise click.ClickException(f"{datapath} is not a directory.")

    click.echo(f"Fetching data from {datapath}...")

    raw_crash_list = generate_raw_crash_list(datapath)

    # Figure out the schema keys to types mapping
    schema_key_logger = SchemaKeyLogger()
    transform_schema(schema=RAW_CRASH_SCHEMA, transform_function=schema_key_logger)

    schema_reducer = SocorroDataReducer(RAW_CRASH_SCHEMA)

    document_keys = DocumentKeys()
    reduced_keys = DocumentKeys()

    total_raw_crash_list = len(raw_crash_list)
    click.echo("")
    click.echo(f"Testing {total_raw_crash_list} raw crash files.")
    for i, path in enumerate(raw_crash_list):
        click.echo(f"Working on {path} ({i+1}/{total_raw_crash_list})...")
        raw_crash = json.loads((datapath / path).read_text())

        # Log the keys
        document_keys.log_keys(raw_crash)

        # Reduce the document by the schema and remove whatever keys are in the document
        # which is what the schema knows about
        reduced_raw_crash = schema_reducer.traverse(raw_crash)
        reduced_keys.log_keys(reduced_raw_crash)

        validate_instance(raw_crash, RAW_CRASH_SCHEMA)

    click.echo("Done testing, all crash reports passed.")

    reduced_keys_keys = set([key for key, type_ in reduced_keys.keys])

    # Figure out which schema keys weren't in documents taking into account
    # pattern_property regexes
    keys_not_in_doc = set()
    for key, type_ in schema_key_logger.keys:
        is_in_reduced_keys = False
        for reduced_key in reduced_keys_keys:
            if match_key(key, reduced_key):
                is_in_reduced_keys = True
                break

        if not is_in_reduced_keys:
            keys_not_in_doc.add((key, type_))

    if keys_not_in_doc:
        click.echo(
            f"{len(keys_not_in_doc)} (out of {len(schema_key_logger.keys)}) "
            + "keys in JSON Schema, but never in any of the tested crashes:"
        )
        click.echo(f"  {'KEY':90}  TYPE(S)")
        for key, val in sorted(keys_not_in_doc):
            click.echo(f"  {key:90}  {val}")

    # Figure out which doc keys aren't in the schema; this also handles cases where the
    # key is in the schema, but is missing a type
    keys_not_in_schema = document_keys.keys - reduced_keys.keys
    if keys_not_in_schema:
        click.echo("")
        click.echo(
            f"{len(keys_not_in_schema)} keys in crash reports but not in schema:"
        )
        click.echo(f"  {'KEY':90}  TYPE(S)")
        for key, val in sorted(keys_not_in_schema):
            click.echo(f"  {key:90}  {val}")

    # Fetch CrashAnnotations.yaml
    resp = session_with_retries().get(CRASH_ANNOTATIONS_URL)
    data = yaml.load(resp.content, Loader=yaml.Loader)
    crash_annotations_keys = set(data.keys())

    schema_keys = set([key[1:] for key, type_ in schema_key_logger.keys])

    keys_not_in_crash_annotations = schema_keys - crash_annotations_keys
    if keys_not_in_crash_annotations:
        click.echo("")
        click.echo(
            f"{len(keys_not_in_crash_annotations)} keys not in CrashAnnotations.yaml:"
        )
        click.echo(f"  {'KEY'}")
        for key in sorted(keys_not_in_crash_annotations):
            click.echo(f"  {key}")

    keys_not_in_raw_crash_schema = crash_annotations_keys - schema_keys
    if keys_not_in_raw_crash_schema:
        click.echo("")
        click.echo(f"{len(keys_not_in_raw_crash_schema)} keys not in raw_crash_schema:")
        click.echo(f"  {'KEY'}")
        for key in sorted(keys_not_in_raw_crash_schema):
            click.echo(f"  {key}")


if __name__ == "__main__":
    validate_and_test()
